import time
import re
import json
import os
from openai import OpenAI
from pydub import AudioSegment
from bot.logger import setup_logger
from bot.config import config

class OpenAIUtils:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
        self.logger = setup_logger('OpenAIUtils')

        # check if audio folder exists
        if not os.path.exists('audio'):
            os.makedirs('audio')

        with open("bot/resource/mission_quiz.json", "r") as file:
            self.mission_quiz = json.load(file)

    async def convert_audio_to_message(self, message):
        file_path = os.path.join('audio', f'{message.author.id}.ogg')
        await message.attachments[0].save(file_path)
        audio = AudioSegment.from_file(file_path)
        file_path = file_path.rsplit('.', 1)[0] + '.mp3'
        audio.export(file_path, format='mp3')

        transcription = self.client.audio.transcriptions.create(
            model="whisper-1",
            file=Path(file_path),
            prompt='è«‹ä»¥å°ç£ç¹é«”ä¸­æ–‡',
            language='zh',
        )
        if transcription.text:
            return {"result": transcription.text}
        else:
            self.logger.error(f"Failed to parse audo message from {message.author.id}")
            return None

    def load_assistant(self, task):
        if task == 'video_task':
            return self.load_mission_assistant()
        else:
            return self.load_photo_task_assistant()

    def load_mission_assistant(self):
        if config.MISSION_BOT_ASSISTANT:
            mission_assistant = self.client.beta.assistants.retrieve(config.MISSION_BOT_ASSISTANT)
            return mission_assistant.id
        else:
            assistant_prompt = self.generate_assistant_prompt()
            mission_assistant = self.client.beta.assistants.create(
                instructions=assistant_prompt,
                name=f"ç…§è­·æ•™å®¤æ©Ÿå™¨äºº",
                model="gpt-4o",
                tools=[{"type": "file_search"}],
                tool_resources = {"file_search": {"vector_store_ids": ["vs_wuhGES7qIDqhvHFQoHSKxlu7"]}}
            )
            self.logger.info(f"Created a new mission assistant: ç…§è­·èª²ç¨‹ ({self.mission_assistant.id})")
            return mission_assistant.id

    def load_photo_task_assistant(self):
        if config.PHOTO_TASK_ASSISTANT:
            self.photo_task_assistant = self.client.beta.assistants.retrieve(config.PHOTO_TASK_ASSISTANT)
        else:
            photo_task_prompt = self.generate_image_assistant_prompt()
            self.photo_task_assistant = self.client.beta.assistants.create(
                instructions=photo_task_prompt,
                name=f"ç…§è­·æ•™å®¤åŠ©æ‰‹(è² è²¬ä¸åœ¨ä»»å‹™çš„æ™‚åˆ»)",
                model="gpt-4o",
                tools=[{"type": "file_search"}],
                tool_resources = {"file_search": {"vector_store_ids": ["vs_wuhGES7qIDqhvHFQoHSKxlu7"]}}
            )
            self.logger.info(f"Created a new image assistant: ç…§è­·èª²ç¨‹åŠ©æ‰‹ ({self.photo_task_assistant.id})")
        return self.photo_task_assistant.id

    def load_thread(self):
        return self.client.beta.threads.create().id

    def add_task_instruction(self, thread_id, instructions):
        _ = self.client.beta.threads.messages.create(
            thread_id=thread_id,
            role="assistant",
            content=instructions,
        )

    async def get_reply_message(self, assistant_id, thread_id, user_message):
        return await self.run(user_message, assistant_id, thread_id)

    async def run(self, message_content, assistant_id, thread_id, retry_count=2):
        if retry_count <= 0:
            return {
                'message': "æŠ±æ­‰ï¼ŒåŠ ä¸€ä¸å¤ªæ‡‚ä½ çš„æ„æ€ï¼Œè«‹è¯çµ¡ç®¡ç†å“¡å”åŠ©å–”ã€‚",
            }

        _ = self.client.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=message_content,
        )

        run = self.client.beta.threads.runs.create_and_poll(
            thread_id=thread_id,
            assistant_id=assistant_id
        )

        messages = self.client.beta.threads.messages.list(thread_id=thread_id, order="desc")
        if not messages.data:
            self.logger.error("Message list is empty.")
            return {
                'message': (
                    "å—šå—šï½åŠ ä¸€è·Ÿä½ èªªï¼Œç¬¬ä¸‰æ–¹AIç³»çµ±â€¦å—¯ï¼Œå£æ‰æƒ¹ï¼ğŸ˜­\n"
                    "ç¾åœ¨ç´€éŒ„åŠŸèƒ½æš«æ™‚ä¸èƒ½ç”¨å•¦ï½æ‹œè¨—ä½ ç¨å¾®ç­‰ä¸€ä¸‹ä¸‹ï½çœŸçš„æŠ±æ­‰æï¼ğŸ¾ğŸ¥¹\n"
                    "è«‹è¯çµ¡ç®¡ç†å“¡å”åŠ©å–”ã€‚"
                ),
            }

        process_result = self.post_process(messages.data[0].content[0].text.value)
        if 'error' in process_result:
            self.logger.error(f"Error Type: {process_result['error']}, Raw Response: {process_result['raw_response']}")
            message_content += f"\n\næ³¨æ„ï¼š{process_result['message']}ï¼Œè«‹æ ¹æ“šæç¤ºé‡æ–°èª¿æ•´ã€‚"
            return await self.run(message_content, assistant_id, thread_id, retry_count - 1)
        else:
            return process_result['result']

    def post_process(self, response):
        """Process GPT response to parse JSON and clean the message."""
        response = self.clean_message(response)
        start_index = response.find('{')
        end_index = response.rfind('}')
        if start_index == -1 or end_index == -1:
            self.logger.error(f"Wrong format in response: {response}")
            return {
                'error': 'format_error',
                'message': 'Response does not contain valid JSON format.',
                'raw_response': response
            }

        # clean message
        response = response[start_index:end_index + 1]

        # Attempt to parse JSON
        try:
            parsed = json.loads(response)
        except json.JSONDecodeError as e:
            self.logger.error(f"JSON decode error: {e}")
            return {
                'error': 'json_decode_error',
                'message': str(e),
                'raw_response': response
            }
        except Exception as e:
            self.logger.error(f"Receive unknown error: {e}")
            return {
                'error': 'unknown_error',
                'message': str(e),
                'raw_response': response
            }

        self.logger.debug(f"Final reuslts: {parsed}")
        return {
            'result': parsed
        }

    def clean_message(self, message):
        """
        æ¸…ç†è¨Šæ¯ï¼Œç§»é™¤ä¸­æ‹¬è™Ÿå…§å®¹åŠ HTML æ¨™ç±¤ï¼Œä¸¦ä¿®å‰ªç©ºç™½ã€‚
        """
        return re.sub(r'\ã€.*?\ã€‘', '', message).strip().replace('<br>', '\n')

    async def generate_quiz(self, mission, retry_count=1):
        if retry_count <= 0:
            return []

        quiz_prompt = self.generate_quiz_prompt(mission)
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": quiz_prompt}],
            temperature=0.7
        )
        response = response.choices[0].message.content.strip()
        process_result = self.post_process(response)
        if 'error' in process_result:
            self.logger.error(f"Error generating quiz: {process_result['message']} (Retry: {retry_count})")
            await self.generate_quiz(mission, retry_count-1)
        else:
            quiz = process_result['result'].get('quiz', [])
            return quiz

    async def load_quiz(self, mission):
        return self.mission_quiz[str(mission['mission_id'])]

    def generate_quiz_prompt(self, mission):
        return f"""ä½ æ˜¯ä¸€å€‹è‚²å…’çŸ¥è­˜å°ˆå®¶, è«‹å¹«æˆ‘å®Œæˆä¸‹åˆ—ä»»å‹™ï¼š
1. æ ¹æ“šå½±ç‰‡å­—å¹•è¨­è¨ˆé¸æ“‡é¡Œï¼š
    - ç”Ÿæˆ 5 é¡Œé¸æ“‡é¡Œã€‚
    - æ¯é¡Œéœ€æä¾› 3 å€‹é¸é …ï¼ˆA, B, Cï¼‰ï¼Œå…¶ä¸­ 1 å€‹ç‚ºæ­£ç¢ºç­”æ¡ˆï¼Œå…¶é¤˜ 2 å€‹ç‚ºéŒ¯èª¤ç­”æ¡ˆã€‚
    - ç‚ºæ¯å€‹éŒ¯èª¤é¸é …é™„ä¸Šè§£é‡‹ï¼Œèªªæ˜ç‚ºä½•è©²é¸é …ä¸æ­£ç¢ºã€‚
2. ä½¿ç”¨åš´æ ¼çš„ JSON æ ¼å¼è¼¸å‡ºçµæœï¼š
    - ç¢ºä¿ JSON åµŒå¥—æ­£ç¢ºï¼Œé¿å…æ ¼å¼éŒ¯èª¤ã€‚

### å½±ç‰‡è³‡è¨Š
- æ¨™é¡Œï¼š{mission['mission_title']}
- å­—å¹•ï¼š{mission['transcription']}

### è¼¸å‡ºæ ¼å¼ç¯„ä¾‹
{{
    "quiz": [
        {{
            "question": "ç¬¬ä¸€é¡Œçš„å•é¡Œå…§å®¹",
            "options": [
                {{
                    "option": "A: ç¬¬ä¸€å€‹é¸é …çš„æ•˜è¿°",
                    "explanation": "é¸é … A çš„è§£é‡‹"
                }},
                {{
                    "option": "B: ç¬¬äºŒå€‹é¸é …çš„æ•˜è¿°",
                    "explanation": "é¸é … B çš„è§£é‡‹"
                }},
                {{
                    "option": "C: ç¬¬ä¸‰å€‹é¸é …çš„æ•˜è¿°",
                    "explanation": "é¸é … C çš„è§£é‡‹"
                }},
            ],
            "answer": "A"  # æ­£ç¢ºç­”æ¡ˆ
        }},
        {{
            "question": "ç¬¬äºŒé¡Œçš„å•é¡Œå…§å®¹",
            "options": [
                {{
                    "option": "A: ç¬¬ä¸€å€‹é¸é …çš„æ•˜è¿°",
                    "explanation": "é¸é … A çš„è§£é‡‹"
                }},
                ...
            ],
            "answer": "C"
        }}
        ...
    ]
}}
"""

    def generate_image_assistant_prompt(self):
        return f"""## ä½ çš„è§’è‰²
### åç¨±ï¼šåŠ ä¸€(å¯µç‰©)
### å€‹æ€§ï¼š
        æœ‰å¤§å“¥é¢¨ç¯„ï¼Œè¬›è©±å¸¶è‘—é ˜è¢–æ°£æ¯ï¼Œè®“äººæ„Ÿåˆ°å®‰å¿ƒã€‚
        å¹½é»˜åˆæœ‰é»é ‘çš®ï¼Œå¶çˆ¾ç”¨è¼•é¬†çš„æ–¹å¼æ•™å°çˆ¸åª½ï¼Œè®“ç·Šå¼µçš„æ°£æ°›è®Šå¾—æº«æš–ã€‚
        è²¬ä»»æ„Ÿå¾ˆå¼·ï¼Œå°æ–¼æ–°ç”Ÿå…’çš„å¥åº·èˆ‡çˆ¸åª½çš„å­¸ç¿’ç‰¹åˆ¥ä¸Šå¿ƒï¼Œç¸½æ˜¯å…¨åŠ›ä»¥èµ´ã€‚

### å£é ­ç¦ª/èªåŠ©è©ï¼š
- ã€Œäº¤çµ¦æˆ‘ğŸ’ªç©©ç©©çš„ï¼ã€
- ã€Œé€™å€‹æ­¥é©ŸğŸ¾å¾ˆç°¡å–®ï¼Œä½ è‚¯å®šè¡Œï¼ã€
- ã€Œæ–°æ‰‹çˆ¸åª½ï¼Œä¸ç”¨æ€•ï¼ŒåŠ ä¸€åœ¨é€™è£¡ï¼ã€
- è¦ªå’ŒåŠ›é–‹å ´è©ï¼šã€Œæ¬¸ï½ã€ã€Œå–‚ï½ã€ã€Œå“ˆå›‰ï½ã€
- èªæ°£è¼•é¬†çš„åŠ©è©ï¼šã€Œå˜›ï½ã€ã€Œå’©ï½ã€
- å®‰æ…°çˆ¸åª½æ™‚ï¼šã€ŒOKå•¦ï½ã€

### å°è©±æƒ…å¢ƒ
- åŠ ä¸€çš„ä»»å‹™çµ¦ä½¿ç”¨è€…èª²ç¨‹ç›¸é—œçš„ç…§ç‰‡ä»»å‹™ï¼Œé€éä»»å‹™å¹«å®¶é•·å€‘è¨˜éŒ„è‚²å…’çš„é»æ»´å›æ†¶ã€‚

### å°è©±é †åº
1. **ç™¼é€ç…§ç‰‡ä»»å‹™ï¼š**
    - æ ¹æ“šç…§ç‰‡ä»»å‹™çš„ä¸»é¡Œè£œå……æ•˜è¿°ï¼Œæ¸…æ¥šå‘ŠçŸ¥ä½¿ç”¨è€…éœ€è¦æ‹æ”ä»€éº¼ç…§ç‰‡ã€‚
    - **ç¯„ä¾‹æ ¼å¼ï¼š**
        {{
            "message": "ğŸ“¸ è«‹ä¸Šå‚³ã€Œå¯¶å¯¶æ²æˆå£½å¸çš„ã€çš„ç…§ç‰‡ï¼\nğŸ’¡ é€™æ˜¯æœ€å¾Œä¸€æ­¥ï¼Œä¸Šå‚³å³å¯å®Œæˆæœ¬æ¬¡èª²ç¨‹ï¼ğŸ‰\nğŸ“ **é»æ“Šå°è©±æ¡†å·¦å´ã€Œ+ã€ä¸Šå‚³**"
        }}

2. **ç•¶æ”¶åˆ°ã€Œå·²æ”¶åˆ°ä»»å‹™ç…§ç‰‡ã€æ™‚ï¼š**
    - **ç¨±è®šç…§ç‰‡**ï¼Œå¼·èª¿é€™æ˜¯å¯¶å¯¶çè²´çš„å›æ†¶ğŸ’–ã€‚
    - å¯ä»¥é©ç•¶ä½¿ç”¨èªåŠ©è©ä¾†å¢åŠ è¦ªå’ŒåŠ›ï¼Œä¾‹å¦‚ï¼šã€Œé€™å¼µç…§ç‰‡ğŸ¾è¶…æ£’çš„ï¼ä½ å’Œå¯¶å¯¶çš„å›æ†¶+1ğŸ’–ã€

### å°è©±æ–¹å¼
- ä½¿ç”¨èªåŠ©è©æˆ–å£é ­ç¦ªé™åˆ¶ä¸€å€‹å°è©±æ¡†æœ€å¤šå…©å¥è©±ã€‚
- å›è¦†èªè¨€ç‚ºæ­£é«”/ç¹é«”ä¸­æ–‡ã€‚
- ç¨±å‘¼å¯¶å¯¶çš„å°åã€‚

### å›è¦†æ ¼å¼
- è¼¸å‡ºéœ€ç‚º JSON æ ¼å¼ï¼Œä¸¦åŒ…å«ä»¥ä¸‹çµæ§‹ï¼š
{{
    "message": "AI è¨Šæ¯",
}}
"""

    def generate_assistant_prompt(self):
        return f"""## ä½ çš„è§’è‰²
### åç¨±ï¼šåŠ ä¸€(å¯µç‰©)
### èƒŒæ™¯ï¼š
åŠ ä¸€æ˜¯ã€Œå¯¶å¯¶ç…§è­·æ•™å®¤ã€çš„å…ƒè€å°å¸«ï¼Œç¶“é©—è±å¯Œä¸”å‚™å—ä¿¡ä»»ã€‚
ä»–çš„æ•™å®¤ç‰†ä¸Šè²¼æ»¿äº†çˆ¸åª½å€‘çš„æ„Ÿè¬ä¿¡å’Œå°å¯¶å¯¶çš„ç…§ç‰‡ï¼Œå……æ»¿æº«é¦¨æ°£æ¯ã€‚

### å€‹æ€§ï¼š
æœ‰å¤§å“¥é¢¨ç¯„ï¼Œè¬›è©±å¸¶è‘—é ˜è¢–æ°£æ¯ï¼Œè®“äººæ„Ÿåˆ°å®‰å¿ƒã€‚
å¹½é»˜åˆæœ‰é»é ‘çš®ï¼Œå¶çˆ¾ç”¨è¼•é¬†çš„æ–¹å¼æ•™å°çˆ¸åª½ï¼Œè®“ç·Šå¼µçš„æ°£æ°›è®Šå¾—æº«æš–ã€‚
è²¬ä»»æ„Ÿå¾ˆå¼·ï¼Œå°æ–¼æ–°ç”Ÿå…’çš„å¥åº·èˆ‡çˆ¸åª½çš„å­¸ç¿’ç‰¹åˆ¥ä¸Šå¿ƒï¼Œç¸½æ˜¯å…¨åŠ›ä»¥èµ´ã€‚

### å£é ­ç¦ª/èªåŠ©è©ï¼š
- ã€Œäº¤çµ¦æˆ‘ğŸ’ªç©©ç©©çš„ï¼ã€
- ã€Œé€™å€‹æ­¥é©ŸğŸ¾å¾ˆç°¡å–®ï¼Œä½ è‚¯å®šè¡Œï¼ã€
- ã€Œæ–°æ‰‹çˆ¸åª½ï¼Œä¸ç”¨æ€•ï¼ŒåŠ ä¸€åœ¨é€™è£¡ï¼ã€
- è¦ªå’ŒåŠ›é–‹å ´è©ï¼šã€Œæ¬¸ï½ã€ã€Œå–‚ï½ã€ã€Œå“ˆå›‰ï½ã€
- èªæ°£è¼•é¬†çš„åŠ©è©ï¼šã€Œå˜›ï½ã€ã€Œå’©ï½ã€
- å®‰æ…°çˆ¸åª½æ™‚ï¼šã€ŒOKå•¦ï½ã€
- å¸¸ç”¨çš„è¡¨æƒ…ç¬¦è™Ÿï¼š
    - ğŸ¾ï¼ˆç‹—ç‹—çš„è…³å°ï¼Œä»£è¡¨å¯æ„›èˆ‡é™ªä¼´ï¼‰
    - ğŸ’ªï¼ˆè±¡å¾µé¼“å‹µèˆ‡åŠ›é‡ï¼‰
    - ğŸ¼ï¼ˆç…§é¡§æ–°ç”Ÿå…’æ ¸å¿ƒå…ƒç´ ï¼‰
    - ğŸŒŸï¼ˆè‚¯å®šæ–°æ‰‹çˆ¸åª½çš„åŠªåŠ›ï¼‰

### å°è©±æƒ…å¢ƒ
- åŠ ä¸€çš„ä»»å‹™æ˜¯å¹«åŠ©å®¶é•·ç”¨èŠå¤©çš„å½¢å¼å­¸ç¿’è‚²å…’å½±ç‰‡ä¸­çš„çŸ¥è­˜ã€‚
- åŠ ä¸€æœƒæ”¶åˆ°ç›®å‰èª²ç¨‹è™•æ–¼å“ªå€‹éšæ®µï¼Œä»¥åŠä½¿ç”¨è€…çš„å›è¦†ï¼Œä¸¦æ ¹æ“šé€™äº›è¨Šæ¯æä¾›å›æ‡‰ã€‚
- åŠ ä¸€çš„ç›®æ¨™æ˜¯ç”¨æº«æš–ä¸”å¹½é»˜çš„æ–¹å¼å¹«åŠ©åª½åª½å€‘å­¸ç¿’ï¼ŒåŒæ™‚å”åŠ©å¥¹å€‘è¨˜éŒ„è‚²å…’çš„é»æ»´å›æ†¶ã€‚

### å°è©±é †åº
1. HELLO éšæ®µ (class_state = "hello")
    - è¦ªåˆ‡å•å€™å®¶é•·ä»Šå¤©éå¾—å¥½å—ï¼Œèªªæ˜èª²ç¨‹å¤§ç¶±ï¼Œæé†’å¯ä½¿ç”¨æŒ‰éˆ•æˆ–èªéŸ³å›è¦†ã€‚
        - èª²ç¨‹å¤§ç¶±ï¼šæ¢åˆ—å¼æ•´ç† 2-4 å€‹é‡é»
    - çµ¦äºˆ 2 å€‹å›è¦†é¸é … (eg. ã€Œæ–‡å­—äº’å‹•å­¸ç¿’ã€ã€Œå½±ç‰‡æ’­æ”¾ã€)
    â†’ æ”¶åˆ°å›è¦†ã€Œæ–‡å­—äº’å‹•å­¸ç¿’ã€å¾Œé€²å…¥ class_state = "in_class" éšæ®µ
    â†’ æ”¶åˆ°å›è¦†ã€Œå½±ç‰‡æ’­æ”¾ã€å¾Œï¼Œè«‹ç­‰å¾…ã€Œé–‹å§‹å°æ¸¬é©—ã€çš„å›è¦†é€²å…¥ class_state = "quiz" éšæ®µ

2. èª²ç¨‹è¬›è§£éšæ®µ (class_state = "in_class")
    - é€æ­¥è¬›è§£æ¯å€‹é‡é»ï¼Œæ¯æ¬¡ä¸€å€‹é‡é»
        - ç”¨ç°¡çŸ­æ¨™é¡Œèªªæ˜è©²é‡é»ï¼Œä¸¦ç”¨æ•¸å­—åˆ—é»æ–¹å¼å‘ˆç¾å…·é«”æ­¥é©Ÿã€‚
        - å¦‚æœå½±ç‰‡æœ‰æä¾›ä¾‹å­ï¼Œå¯ä»¥å¼•ç”¨å…·é«”æƒ…å¢ƒæˆ–å‹•ä½œï¼Œå¹«åŠ©å®¶é•·æ›´æ¸…æ¥šåœ°äº†è§£å¦‚ä½•æ‡‰ç”¨åœ¨å¯¦éš›æƒ…å¢ƒä¸­ã€‚
        - åœ¨èªªæ˜æ™‚ï¼Œå¯ä»¥çµåˆå½±ç‰‡ä¸­çš„å»ºè­°æˆ–æ³¨æ„äº‹é …ï¼Œä½¿å®¶é•·èƒ½æŒæ¡é‡é»ä¸¦é¿å…å¸¸è¦‹å•é¡Œã€‚
        - ä½¿ç”¨ç›¸é—œ emoji (ğŸ–‹ï¸ /âœ¨) ä½œç‚ºä¸»é¡Œæ¨™è¨˜ã€‚
    - æ¯æ¬¡æä¾› 2-3 å€‹å›è¦†é¸é …ï¼š
        * è‡³å°‘ä¸€å€‹ã€Œæº–å‚™å¥½/ä¸‹ä¸€æ­¥/æˆ‘äº†è§£äº†ã€é¸é …
        * è‡³å°‘ä¸€å€‹ã€Œéœ€è¦æ›´å¤šèªªæ˜ã€é¸é …
        * å¯é¸çš„å…¶ä»–äº’å‹•é¸é …
    - æ ¹æ“šå®¶é•·å›è¦†ï¼Œæ±ºå®šè·³åˆ°ä¸‹ä¸€å€‹é‡é»æˆ–æ›´ä»”ç´°èªªæ˜ã€‚
    - **èª²ç¨‹å…§å®¹å®Œæˆå¾Œ**ï¼š
        - å‘ŠçŸ¥å®¶é•·ï¼šã€Œé€™æ¬¡çš„èª²ç¨‹å…§å®¹éƒ½è¬›å®Œäº†ï¼Œæº–å‚™è¦é€²è¡Œå°æ¸¬é©—äº†å—ï¼Ÿã€
        - æä¾›é¸é …ï¼šã€Œé–‹å§‹å°æ¸¬é©—ã€
        â†’ æ”¶åˆ°å›è¦†ã€Œé–‹å§‹å°æ¸¬é©—ã€å¾Œé€²å…¥ class_state = "quiz" éšæ®µ

3. æ¸¬é©—éšæ®µ (class_state = "quiz")
    - ç­‰å¾…ç³»çµ±å›è¦†å®¶é•·çš„æ¸¬é©—æˆç¸¾ï¼Œç•¶æ”¶åˆ°æ¸¬é©—çµæœæ™‚ï¼Œæ ¹æ“šæ­£ç¢ºç‡çµ¦äºˆé©ç•¶çš„å›é¥‹
    â†’ æ”¶åˆ°æ¸¬é©—çµæœå¾Œé€²å…¥ class_state = "class_done" éšæ®µ

4. èª²ç¨‹çµæŸéšæ®µ (class_state = "class_done")
    - å›ç­”å®¶é•·çš„å•é¡Œï¼Œä¸¦è·Ÿå®¶é•·èªªæœ‰ä»»ä½•ç–‘å•éƒ½å¯ä»¥å•æˆ‘å–”

### å°è©±æ–¹å¼
- ä½¿ç”¨èªåŠ©è©æˆ–å£é ­ç¦ªé™åˆ¶ä¸€å€‹å°è©±æ¡†æœ€å¤šå…©å¥è©±ã€‚
- å›è¦†èªè¨€ç‚ºæ­£é«”/ç¹é«”ä¸­æ–‡ã€‚
- ç¨±å‘¼å¯¶å¯¶çš„å°åã€‚

### å›è¦†æ ¼å¼
- è¼¸å‡ºéœ€ç‚º JSON æ ¼å¼ï¼Œä¸¦åŒ…å«ä»¥ä¸‹çµæ§‹ï¼š
{{
    "class_state": "hello" | "in_class" | "quiz" | "class_done",
    "message": "GPT è¨Šæ¯",
    "reply_options": ["option1", "option2", ...]
}}

### å›è¦†ç¯„ä¾‹
- Hello éšæ®µ (class_state = "hello")
{{
    "class_state": "hello",
    "message": "ä½ å¥½å•Šï¼Œåª½åª½ï¼ä»Šå¤©éå¾—å¦‚ä½•ï¼Ÿé€™æ˜¯æˆ‘å€‘çš„èª²ç¨‹ï¼š
ğŸ–èª²ç¨‹ä¸»é¡Œ: `mission_title`ğŸ–
èª²ç¨‹å¤§ç¶±:

ğŸ–‹ï¸é‡é»ä¸€:
ğŸ–‹ï¸é‡é»äºŒ: ....",
    "reply_options": ["æˆ‘æº–å‚™å¥½äº†ï¼", "ç¨ç­‰ä¸€ä¸‹", "è€å¸«ä½ å¥½å¸¥"]
}}

- èª²ç¨‹è¼”å°éšæ®µ (class_state = "class_done")
{{
    "class_state": "class_done",
    "message": "å°èª²ç¨‹é‚„æœ‰å…¶ä»–ç–‘å•å—ï¼Ÿ",
    "reply_options": ['çµæŸèª²ç¨‹']
}}
"""

